import { ipcMain } from 'electron';
import * as lancedbService from '../lancedb/index.js';
import { getMainProcessMemoryService } from '../memory/persistentMemoryService.js';
import { getDatabase } from '../database/index.js';
import { logger } from '../utils/logger.js';
import type { SaveMemoryRequest, SavePermanentMemoryRequest, UpdateMemoryRequest, MemoryFilters, Result } from '../types/ipc.js';
import { success, failure } from '../types/ipc.js';

/**
 * æ³¨å†Œ LanceDB ç›¸å…³çš„ IPC å¤„ç†å™¨
 */
export function registerLanceDBHandlers(): void {
  logger.info('[LanceDBHandlers] Registering LanceDB IPC handlers');

  // åˆå§‹åŒ– LanceDB
  ipcMain.handle('lancedb:init', async () => {
    try {
      await lancedbService.initLanceDB();
      logger.info('[LanceDBHandlers] LanceDB initialized successfully');
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to initialize LanceDB', error);
      throw error;
    }
  });

  // æ·»åŠ å‘é‡æ•°æ®
  ipcMain.handle('lancedb:add', async (_, chunks) => {
    try {
      await lancedbService.addVectors(chunks);
      logger.info('[LanceDBHandlers] Vectors added', { count: chunks.length });
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to add vectors', error);
      throw error;
    }
  });

  // æœç´¢å‘é‡
  ipcMain.handle('lancedb:search', async (_, queryVector, limit) => {
    try {
      const results = await lancedbService.searchVectors(queryVector, limit);
      logger.info('[LanceDBHandlers] Vector search completed', { resultCount: results.length });
      return results;
    } catch (error) {
      logger.error('[LanceDBHandlers] Vector search failed', error);
      throw error;
    }
  });

  // åˆ é™¤æŒ‡å®šæ–‡ä»¶çš„å‘é‡
  ipcMain.handle('lancedb:deleteByFile', async (_, fileId) => {
    try {
      await lancedbService.deleteByFile(fileId);
      logger.info('[LanceDBHandlers] Vectors deleted for file', { fileId });
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to delete vectors', { fileId, error });
      throw error;
    }
  });

  // åˆ é™¤æŒ‡å®š ID çš„å‘é‡
  ipcMain.handle('lancedb:deleteById', async (_, id) => {
    try {
      await lancedbService.deleteById(id);
      logger.info('[LanceDBHandlers] Vector deleted by ID', { id });
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to delete vector by ID', { id, error });
      throw error;
    }
  });

  // æ¸…ç©ºæ‰€æœ‰å‘é‡
  ipcMain.handle('lancedb:clear', async () => {
    try {
      await lancedbService.clearAll();
      logger.info('[LanceDBHandlers] All vectors cleared');
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to clear vectors', error);
      throw error;
    }
  });

  // è·å–æ‰€æœ‰å‘é‡å—
  ipcMain.handle('lancedb:getAll', async () => {
    try {
      const chunks = await lancedbService.getAllChunks();
      logger.info('[LanceDBHandlers] Retrieved all chunks', { count: chunks.length });
      return chunks;
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to get all chunks', error);
      throw error;
    }
  });

  // è·å–æ‰€æœ‰æ–‡ä»¶ ID
  ipcMain.handle('lancedb:getFileIds', async () => {
    try {
      const fileIds = await lancedbService.getFileIds();
      logger.info('[LanceDBHandlers] Retrieved file IDs', { count: fileIds.length });
      return fileIds;
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to get file IDs', error);
      throw error;
    }
  });

  // è·å–ç»Ÿè®¡ä¿¡æ¯
  ipcMain.handle('lancedb:getStats', async () => {
    try {
      const stats = await lancedbService.getStats();
      logger.info('[LanceDBHandlers] Retrieved stats', stats);
      return stats;
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to get stats', error);
      throw error;
    }
  });

  // è·å–æ–‡ä»¶ååˆ°fileIdçš„æ˜ å°„
  ipcMain.handle('lancedb:getFileNameMapping', async () => {
    try {
      const mapping = await lancedbService.getFileNameMapping();
      // å°† Map è½¬æ¢ä¸ºæ™®é€šå¯¹è±¡ä»¥ä¾¿ IPC ä¼ è¾“
      const result: Record<string, string[]> = {};
      for (const [key, value] of mapping) {
        result[key] = value;
      }
      logger.info('[LanceDBHandlers] Retrieved file name mapping', { count: Object.keys(result).length });
      return result;
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to get file name mapping', error);
      throw error;
    }
  });

  // æ¸…ç†é‡å¤æ–‡ä»¶åçš„æ—§ç‰ˆæœ¬æ•°æ®
  ipcMain.handle('lancedb:cleanDuplicateFileNames', async (_event, fileNameToKeepId: Record<string, string>) => {
    try {
      const mapping = new Map(Object.entries(fileNameToKeepId));
      const deletedCount = await lancedbService.cleanDuplicateFileNames(mapping);
      logger.info('[LanceDBHandlers] Cleaned duplicate file names', { deletedCount });
      return deletedCount;
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to clean duplicate file names', error);
      throw error;
    }
  });

  // è·å–æ–‡ä»¶å…ƒæ•°æ®ï¼ˆfileId -> lastModified æ˜ å°„ï¼‰
  ipcMain.handle('lancedb:getFileMetadata', async () => {
    try {
      const metadata = await lancedbService.getFileMetadata();
      // å°† Map è½¬æ¢ä¸ºæ™®é€šå¯¹è±¡ä»¥ä¾¿ IPC ä¼ è¾“
      const result: Record<string, number> = {};
      for (const [key, value] of metadata) {
        result[key] = value;
      }
      logger.info('[LanceDBHandlers] Retrieved file metadata', { count: Object.keys(result).length });
      return result;
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to get file metadata', error);
      throw error;
    }
  });

  // æœç´¢æ°¸ä¹…è®°å¿†
  ipcMain.handle('memory:search', async (_, query: string, limit: number = 5) => {
    try {
      const service = getMainProcessMemoryService();
      const results = await service.searchMemories(query, limit);
      logger.info('[LanceDBHandlers] Memory search completed', { query, resultCount: results.length });
      return results;
    } catch (error) {
      logger.error('[LanceDBHandlers] Memory search failed', { query, error });
      return [];
    }
  });

  // ä¿å­˜æ°¸ä¹…è®°å¿†
  ipcMain.handle('memory:save', async (_, memory: SaveMemoryRequest) => {
    try {
      const service = getMainProcessMemoryService();

      // è½¬æ¢ SaveMemoryRequest ä¸º MemoryDocument
      const memoryId = memory.id || `mem_${Date.now()}_${Math.random().toString(36).substring(2, 8)}`;
      const now = Date.now();
      const memoryDocument = {
        id: memoryId,
        filePath: '', // ç”± service.generateFileName ç”Ÿæˆ
        content: memory.content,
        topics: memory.topics || [],
        importance: memory.importance || 'medium',
        sourceSessions: [],
        created: now,
        updated: now,
        title: memory.title,
        summary: memory.summary,
        category: memory.category,
      };

      await service.saveMemory(memoryDocument);
      logger.info('[LanceDBHandlers] Memory saved successfully', { id: memoryId });
      return success(true);
    } catch (error) {
      logger.error('[LanceDBHandlers] Memory save failed', { id: memory?.id, error });
      return failure((error as Error).message);
    }
  });

  // è·å–æ‰€æœ‰è®°å¿†
  ipcMain.handle('memory:getAll', async () => {
    try {
      const service = getMainProcessMemoryService();
      const memories = await service.getAllMemories();
      logger.info('[LanceDBHandlers] Get all memories completed', { count: memories.length });
      return memories;
    } catch (error) {
      logger.error('[LanceDBHandlers] Get all memories failed', error);
      return [];
    }
  });

  // æ£€æŸ¥è®°å¿†æ–‡ä»¶åŒæ­¥çŠ¶æ€
  ipcMain.handle('memory:checkSyncStatus', async () => {
    try {
      const { app } = await import('electron');
      const path = await import('path');
      const fs = await import('fs');
      const memoriesDir = path.join(app.getPath('userData'), '.memories');
      const indexPath = path.join(memoriesDir, '_memories_index.json');

      if (!fs.existsSync(indexPath)) {
        return { needsSync: false, outdatedFiles: [] };
      }

      const indexData = fs.readFileSync(indexPath, 'utf-8');
      const index = JSON.parse(indexData);
      const outdatedFiles: string[] = [];

      for (const memory of index.memories || []) {
        if (fs.existsSync(memory.filePath)) {
          const stats = fs.statSync(memory.filePath);
          const fileMtime = new Date(stats.mtime).getTime();
          const indexedMtime = new Date(memory.updated).getTime();

          if (fileMtime > indexedMtime) {
            outdatedFiles.push(memory.id);
          }
        }
      }

      logger.info('[LanceDBHandlers] Memory sync check completed', {
        totalMemories: index.memories?.length || 0,
        outdatedCount: outdatedFiles.length
      });

      return {
        needsSync: outdatedFiles.length > 0,
        outdatedFiles
      };
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to check memory sync status', error);
      return { needsSync: false, outdatedFiles: [] };
    }
  });

  // æ›´æ–°è®°å¿†å†…å®¹
  ipcMain.handle('memory:update', async (_, data: UpdateMemoryRequest) => {
    logger.debug('[LanceDB][memory:update] Received request', { id: data.id });

    try {
      const service = getMainProcessMemoryService();
      const memory = await service.getMemoryById(data.id);

      if (!memory) {
        logger.warn('[LanceDB][memory:update] Memory not found', { id: data.id });
        return failure('Memory not found');
      }

      memory.content = data.content;
      memory.updated = data.updatedAt || Date.now();

      await service.saveMemory(memory);

      logger.info('[LanceDBHandlers] Memory updated successfully', { id: data.id });
      return success(true);
    } catch (error) {
      logger.error('[LanceDBHandlers] Memory update failed', { id: data?.id, error });
      return failure((error as Error).message);
    }
  });

  // æ ‡æ˜Ÿ/å–æ¶ˆæ ‡æ˜Ÿ
  ipcMain.handle('memory:star', async (_, id: string, isStarred: boolean) => {
    logger.debug('[LanceDB][memory:star] Received request', { id, isStarred });

    try {
      const service = getMainProcessMemoryService();
      const memory = await service.getMemoryById(id);

      if (!memory) {
        logger.warn('[LanceDB][memory:star] Memory not found', { id });
        return failure('Memory not found');
      }

      memory.importance = isStarred ? 'high' : 'medium';
      await service.saveMemory(memory);

      logger.info('[LanceDBHandlers] Memory starred toggled', { id, isStarred });
      return success(true);
    } catch (error) {
      logger.error('[LanceDBHandlers] Memory star toggle failed', { id, error });
      return failure((error as Error).message);
    }
  });

  // è·å–æ‰€æœ‰è®°å¿†ï¼ˆå¸¦ç­›é€‰ï¼‰
  ipcMain.handle('memory:getMemories', async (_, filters?: MemoryFilters) => {
    try {
      const service = getMainProcessMemoryService();
      let memories = await service.getAllMemories();

      if (filters) {
        if (filters.isStarred !== undefined) {
          memories = memories.filter(m => m.importance === 'high');
        }
        if (filters.importance) {
          memories = memories.filter(m => m.importance === filters.importance);
        }
      }

      return memories;
    } catch (error) {
      logger.error('[LanceDBHandlers] Get memories failed', error);
      return [];
    }
  });

  // è·å–ä¸­æœŸè®°å¿†ï¼ˆç”¨äºè‡ªåŠ¨å‡çº§ï¼‰
  ipcMain.handle('memory:getMidTermMemories', async () => {
    try {
      const { chatRepository } = await import('../database/repositories/chatRepository.js');
      const sessions = chatRepository.getAllCompactedSessions();
      
      const memories = sessions.map(session => ({
        id: session.id,
        sessionId: session.session_id,
        summary: session.summary,
        content: session.summary,
        topics: session.key_topics || [],
        createdAt: session.created_at,
        lastAccessedAt: session.last_accessed_at || session.created_at,
        accessCount: session.access_count || 0,
        isStarred: session.decisions?.length > 0,
      }));

      logger.info('[LanceDBHandlers] Retrieved mid-term memories', { count: memories.length });
      return memories;
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to get mid-term memories', error);
      return [];
    }
  });

  // ğŸ”§ æ–°å¢: æ›´æ–°è®°å¿†è®¿é—®ä¿¡æ¯
  ipcMain.handle('memory:updateAccess', async (_, sessionId: string) => {
    try {
      const { chatRepository } = await import('../database/repositories/chatRepository.js');
      chatRepository.updateMemoryAccess(sessionId);
      logger.debug('[LanceDBHandlers] Memory access updated', { sessionId });
      return true;
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to update memory access', error);
      return false;
    }
  });

  // è·å–æ‰€æœ‰æ ‡æ˜Ÿè®°å¿†
  ipcMain.handle('memory:getStarredMemories', async () => {
    try {
      const service = getMainProcessMemoryService();
      const memories = await service.getAllMemories();
      
      const starredMemories = memories
        .filter(m => m.importance === 'high')
        .map(m => ({
          id: m.id,
          sessionId: m.sourceSessions?.[0] || '',
          summary: m.content.substring(0, 200),
          content: m.content,
          topics: m.topics,
          createdAt: m.created,
          lastAccessedAt: m.updated,
          accessCount: m.accessCount || 0,
          isStarred: true,
        }));

      logger.info('[LanceDBHandlers] Retrieved starred memories', { count: starredMemories.length });
      return starredMemories;
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to get starred memories', error);
      return [];
    }
  });

  // ä¿å­˜æ°¸ä¹…è®°å¿†ï¼ˆå¸¦å®Œæ•´æ¨¡æ¿ï¼‰
  ipcMain.handle('memory:savePermanent', async (_, memoryData: SavePermanentMemoryRequest) => {
    try {
      const service = getMainProcessMemoryService();
      const { app } = await import('electron');
      const p = await import('path');
      
      // ç”Ÿæˆå”¯ä¸€ ID å’Œæ–‡ä»¶å
      const memoryId = memoryData.id || `permanent_${Date.now()}_${Math.random().toString(36).substring(2, 8)}`;
      const fileName = `${memoryId}.md`;
      const filePath = p.join(app.getPath('userData'), '.memories', fileName);
      
      // æå–æ ‡é¢˜ï¼ˆä»å†…å®¹æˆ–æä¾›ï¼‰
      let title = memoryData.title;
      if (!title && memoryData.content) {
        const titleMatch = memoryData.content.match(/^#\s+(.+)$/m);
        title = titleMatch ? titleMatch[1].substring(0, 100) : memoryData.content.substring(0, 50);
      }
      title = title || 'Untitled Memory';
      
      // æ„å»ºå®Œæ•´çš„è®°å¿†å¯¹è±¡ï¼ˆåŒ¹é… PermanentMemoryTemplateï¼‰
      const memory = {
        id: memoryId,
        title,
        filePath,
        content: memoryData.content,
        summary: memoryData.summary || memoryData.content?.substring(0, 200),
        sourcePath: memoryData.sourcePath || '',
        sourceType: memoryData.sourceType || 'manual',
        created: memoryData.createdAt || Date.now(),
        updated: Date.now(),
        lastAccessedAt: Date.now(),
        topics: memoryData.topics || [],
        category: memoryData.category,
        importance: memoryData.importance || 'medium',
        isStarred: memoryData.isStarred || false,
        accessCount: 0,
        sourceSessions: memoryData.promotedFrom ? [memoryData.promotedFrom] : [],
        promotedFrom: memoryData.promotedFrom || undefined,
        promotedAt: memoryData.promotedAt || undefined,
      };
      
      await service.saveMemory(memory);
      logger.info('[LanceDBHandlers] Permanent memory saved', { id: memoryId, title });
      return success({ id: memoryId });
    } catch (error) {
      logger.error('[LanceDBHandlers] Save permanent memory failed', error);
      return failure((error as Error).message);
    }
  });

  // ğŸ”§ ä¿®å¤: æ ‡è®°ä¸­æœŸè®°å¿†ä¸ºå·²å‡çº§
  // æ­£ç¡®çš„è¡Œä¸ºï¼šæ›´æ–° compacted_sessions è¡¨ä¸­çš„è®°å½•ï¼Œæ ‡è®°ä¸ºå·²å‡çº§
  ipcMain.handle('memory:markAsPromoted', async (_, originalId: string) => {
    try {
      const { chatRepository } = await import('../database/repositories/chatRepository.js');
      const db = getDatabase();
      
      // 1. éªŒè¯åŸå§‹è®°å½•å­˜åœ¨
      const sessions = chatRepository.getCompactedSessions(originalId);
      if (sessions.length === 0) {
        logger.warn('[LanceDBHandlers] Compacted session not found', { originalId });
        return failure('Compacted session not found');
      }
      
      const originalSession = sessions[0];
      const now = Date.now();
      
      // 2. æ„å»ºå‡çº§å†å²
      const existingHistory = originalSession.promotion_history 
        ? JSON.parse(originalSession.promotion_history) 
        : [];
      const newHistory = [...existingHistory, {
        from: 'mid-term',
        to: 'long-term',
        at: now,
        reason: 'Auto-upgrade by MemoryAutoUpgradeService'
      }];
      
      // 3. æ›´æ–° compacted_sessions è¡¨
      db.prepare(`
        UPDATE compacted_sessions
        SET tier = 'long-term',
            tier_updated_at = ?,
            promotion_history = ?
        WHERE id = ?
      `).run(
        now,
        JSON.stringify(newHistory),
        originalId
      );
      
      // 4. è®°å½•åˆ° promotion log è¡¨
      const logId = `prom-${Date.now()}-${Math.random().toString(36).substring(2, 9)}`;
      db.prepare(`
        INSERT INTO memory_promotion_log
        (id, original_id, source_tier, target_tier, promoted_at, reason, success)
        VALUES (?, ?, 'mid-term', 'long-term', ?, 'Auto-upgrade', true)
      `).run(logId, originalId, now);
      
      logger.info('[LanceDBHandlers] Memory marked as promoted', { 
        originalId, 
        newTier: 'long-term',
        historyCount: newHistory.length 
      });
      
      return success({
        success: true,
        originalId,
        newTier: 'long-term',
        promotedAt: now
      });
    } catch (error) {
      logger.error('[LanceDBHandlers] Mark as promoted failed', error);
      return failure((error as Error).message);
    }
  });

  // ğŸ”§ æ–°å¢: è¿è¡Œæ¸…ç†æµç¨‹
  ipcMain.handle('memory:runCleanup', async () => {
    try {
      const db = getDatabase();
      const { chatRepository } = await import('../database/repositories/chatRepository.js');
      const report = {
        expiredMidTerm: 0,
        orphanedVectors: 0,
        danglingPromotions: 0,
        errors: [] as string[],
        freedSpace: 0,
      };

      // 1. æ¸…ç†è¿‡æœŸä¸­æœŸè®°å¿†
      const thirtyDaysAgo = Date.now() - (30 * 24 * 60 * 60 * 1000);
      const expiredRows = db.prepare(`
        SELECT id FROM compacted_sessions
        WHERE tier = 'mid-term'
          AND created_at < ?
          AND (last_accessed_at < ? OR last_accessed_at IS NULL)
      `).all(thirtyDaysAgo, thirtyDaysAgo) as { id: string }[];

      for (const row of expiredRows) {
        try {
          chatRepository.deleteCompactedSession(row.id);
          report.expiredMidTerm++;
        } catch (e) {
          report.errors.push(`Failed to delete ${row.id}: ${e}`);
        }
      }

      // 2. ä¿®å¤æ‚¬æŒ‚çš„å‡çº§
      const dangling = db.prepare(`
        SELECT id, promotion_history FROM compacted_sessions
        WHERE tier = 'promoted'
      `).all() as { id: string; promotion_history: string }[];

      for (const row of dangling) {
        try {
          const history = JSON.parse(row.promotion_history || '[]');
          const lastPromotion = history[history.length - 1];
          if (lastPromotion && lastPromotion.targetTier === 'long-term' && lastPromotion.promotedAt) {
            db.prepare(`
              UPDATE compacted_sessions
              SET tier = 'long-term', tier_updated_at = ?
              WHERE id = ?
            `).run(lastPromotion.promotedAt, row.id);
            report.danglingPromotions++;
          }
        } catch (e) {
          // å¿½ç•¥
        }
      }

      // 3. ç»Ÿè®¡å­¤ç«‹å‘é‡
      const sessionRows = db.prepare('SELECT id FROM compacted_sessions').all() as { id: string }[];
      const sessionIds = new Set(sessionRows.map(r => r.id));
      const vectorRows = db.prepare('SELECT DISTINCT file_id FROM vector_chunks').all() as { file_id: string }[];
      report.orphanedVectors = vectorRows.filter(c => !sessionIds.has(c.file_id)).length;

      logger.info('[LanceDBHandlers] Cleanup completed', report);
      return report;
    } catch (error) {
      logger.error('[LanceDBHandlers] Cleanup failed', error);
      return {
        expiredMidTerm: 0,
        orphanedVectors: 0,
        danglingPromotions: 0,
        errors: [(error as Error).message],
        freedSpace: 0,
      };
    }
  });

  // ğŸ”§ æ–°å¢: è·å–æ¸…ç†ç»Ÿè®¡
  ipcMain.handle('memory:getCleanupStats', async () => {
    try {
      const db = getDatabase();
      const { app } = await import('electron');
      const path = await import('path');
      const fs = await import('fs');
      
      const midTermResult = db.prepare(
        'SELECT COUNT(*) as count FROM compacted_sessions WHERE tier = ?'
      ).get('mid-term') as { count: number };
      const longTermResult = db.prepare(
        'SELECT COUNT(*) as count FROM compacted_sessions WHERE tier = ?'
      ).get('long-term') as { count: number };
      const expiredResult = db.prepare(
        'SELECT COUNT(*) as count FROM compacted_sessions WHERE tier = ? AND created_at < ?'
      ).get('mid-term', Date.now() - (30 * 24 * 60 * 60 * 1000)) as { count: number };
      const danglingResult = db.prepare(
        'SELECT COUNT(*) as count FROM compacted_sessions WHERE tier = ?'
      ).get('promoted') as { count: number };

      // ğŸ†• è®¡ç®— .memories æ–‡ä»¶å¤¹ä¸­çš„ .md æ–‡ä»¶æ•°é‡
      let persistentFiles = 0;
      const memoriesDir = path.join(app.getPath('userData'), '.memories');
      if (fs.existsSync(memoriesDir)) {
        const files = fs.readdirSync(memoriesDir);
        persistentFiles = files.filter((f: string) => 
          f.endsWith('.md') && !f.startsWith('_')
        ).length;
      }

      return {
        expiredCount: expiredResult?.count || 0,
        orphanedCount: 0,
        danglingCount: danglingResult?.count || 0,
        totalMidTerm: midTermResult?.count || 0,
        totalLongTerm: longTermResult?.count || 0,
        persistentFiles,
      };
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to get cleanup stats', error);
      return {
        expiredCount: 0,
        orphanedCount: 0,
        danglingCount: 0,
        totalMidTerm: 0,
        totalLongTerm: 0,
        persistentFiles: 0,
      };
    }
  });

  // ğŸ”§ æ–°å¢: æ¸…ç†å­¤ç«‹å‘é‡
  ipcMain.handle('memory:cleanupOrphanedVectors', async () => {
    try {
      const db = getDatabase();
      const result = { deleted: 0, errors: [] as string[] };

      const sessionRows = db.prepare('SELECT id FROM compacted_sessions').all() as { id: string }[];
      const sessionIds = new Set(sessionRows.map(r => r.id));
      const vectorRows = db.prepare('SELECT DISTINCT file_id FROM vector_chunks').all() as { file_id: string }[];

      for (const chunk of vectorRows) {
        if (!sessionIds.has(chunk.file_id)) {
          try {
            db.prepare('DELETE FROM vector_chunks WHERE file_id = ?').run(chunk.file_id);
            result.deleted++;
          } catch (e) {
            result.errors.push(`Failed to delete ${chunk.file_id}: ${e}`);
          }
        }
      }

      logger.info('[LanceDBHandlers] Cleaned orphaned vectors:', result);
      return result;
    } catch (error) {
      logger.error('[LanceDBHandlers] Failed to cleanup orphaned vectors', error);
      return { deleted: 0, errors: [(error as Error).message] };
    }
  });

  logger.info('[LanceDBHandlers] LanceDB IPC handlers registered successfully');
}
